
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_example/plot_example_GEKPLS.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_example_plot_example_GEKPLS.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_example_plot_example_GEKPLS.py:


Use of GEKPLS
-------------

.. GENERATED FROM PYTHON SOURCE LINES 7-15

.. code-block:: default


    from smt.sampling_methods import LHS
    from smt.problems import Sphere
    from smt.surrogate_models import GEKPLS
    import numpy as np
    import otsmt









.. GENERATED FROM PYTHON SOURCE LINES 16-17

| Definition of Initial data

.. GENERATED FROM PYTHON SOURCE LINES 17-31

.. code-block:: default


       
    # Construction of the DOE
    fun = Sphere(ndim=2)
    sampling = LHS(xlimits=fun.xlimits, criterion="m")
    xt = sampling(40)
    yt = fun(xt)
    # Compute the gradient
    for i in range(2):
        yd = fun(xt, kx=i)
        yt = np.concatenate((yt, yd), axis=1)
       
    xv= sampling(10)
    







.. GENERATED FROM PYTHON SOURCE LINES 32-33

| Training of smt model for GEKPLS

.. GENERATED FROM PYTHON SOURCE LINES 33-49

.. code-block:: default


    n_comp = 2
    sm_gekpls = GEKPLS(
                        theta0=[1e-2] * n_comp,
                        xlimits=fun.xlimits,
                        extra_points=1,
                        print_prediction=False,
                        n_comp=n_comp,
                        )
    sm_gekpls.set_training_values(xt, yt[:, 0][:,np.newaxis])
    
    for i in range(2):
       sm_gekpls.set_training_derivatives(xt, yt[:, 1 + i].reshape((yt.shape[0], 1)), i)
    sm_gekpls.train()






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    ___________________________________________________________________________
   
                                      GEKPLS
    ___________________________________________________________________________
   
     Problem size
   
          # training points.        : 40
   
    ___________________________________________________________________________
   
     Training
   
       Training ...
    /usr/share/miniconda3/envs/test/lib/python3.9/site-packages/scikit_learn-1.1.1-py3.9-linux-x86_64.egg/sklearn/cross_decomposition/_pls.py:304: UserWarning: Y residual is constant at iteration 1
      warnings.warn(f"Y residual is constant at iteration {k}")
    /usr/share/miniconda3/envs/test/lib/python3.9/site-packages/scikit_learn-1.1.1-py3.9-linux-x86_64.egg/sklearn/cross_decomposition/_pls.py:304: UserWarning: Y residual is constant at iteration 1
      warnings.warn(f"Y residual is constant at iteration {k}")
    /usr/share/miniconda3/envs/test/lib/python3.9/site-packages/scikit_learn-1.1.1-py3.9-linux-x86_64.egg/sklearn/cross_decomposition/_pls.py:304: UserWarning: Y residual is constant at iteration 1
      warnings.warn(f"Y residual is constant at iteration {k}")
    /usr/share/miniconda3/envs/test/lib/python3.9/site-packages/scikit_learn-1.1.1-py3.9-linux-x86_64.egg/sklearn/cross_decomposition/_pls.py:304: UserWarning: Y residual is constant at iteration 1
      warnings.warn(f"Y residual is constant at iteration {k}")
    /usr/share/miniconda3/envs/test/lib/python3.9/site-packages/scikit_learn-1.1.1-py3.9-linux-x86_64.egg/sklearn/cross_decomposition/_pls.py:304: UserWarning: Y residual is constant at iteration 1
      warnings.warn(f"Y residual is constant at iteration {k}")
    /usr/share/miniconda3/envs/test/lib/python3.9/site-packages/scikit_learn-1.1.1-py3.9-linux-x86_64.egg/sklearn/cross_decomposition/_pls.py:304: UserWarning: Y residual is constant at iteration 1
      warnings.warn(f"Y residual is constant at iteration {k}")
    /usr/share/miniconda3/envs/test/lib/python3.9/site-packages/scikit_learn-1.1.1-py3.9-linux-x86_64.egg/sklearn/cross_decomposition/_pls.py:304: UserWarning: Y residual is constant at iteration 1
      warnings.warn(f"Y residual is constant at iteration {k}")
    /usr/share/miniconda3/envs/test/lib/python3.9/site-packages/scikit_learn-1.1.1-py3.9-linux-x86_64.egg/sklearn/cross_decomposition/_pls.py:304: UserWarning: Y residual is constant at iteration 1
      warnings.warn(f"Y residual is constant at iteration {k}")
    /usr/share/miniconda3/envs/test/lib/python3.9/site-packages/scikit_learn-1.1.1-py3.9-linux-x86_64.egg/sklearn/cross_decomposition/_pls.py:304: UserWarning: Y residual is constant at iteration 1
      warnings.warn(f"Y residual is constant at iteration {k}")
    /usr/share/miniconda3/envs/test/lib/python3.9/site-packages/scikit_learn-1.1.1-py3.9-linux-x86_64.egg/sklearn/cross_decomposition/_pls.py:304: UserWarning: Y residual is constant at iteration 1
      warnings.warn(f"Y residual is constant at iteration {k}")
       Training - done. Time (sec):  0.1313114




.. GENERATED FROM PYTHON SOURCE LINES 50-51

| Creation of OpenTurns PythonFunction for prediction

.. GENERATED FROM PYTHON SOURCE LINES 51-61

.. code-block:: default


    otgekpls = otsmt.smt2ot(sm_gekpls)
    otgekplsprediction = otgekpls.getPredictionFunction()
    otgekplsvariances = otgekpls.getConditionalVarianceFunction()
    otgekplsfirstderivatives = otgekpls.getPredictionDerivativesFunction(0)
    otgekplssecondderivatives = otgekpls.getPredictionDerivativesFunction(1)

    print('Predicted values by GEKPLS:',otgekplsprediction(xv))    
    print('Predicted variances values by GEKPLS:',otgekplsvariances(xv))    
    print('Predicted mean first derivatives by GEKPLS:',otgekplsfirstderivatives(xv))    
    print('Predicted mean second derivatives by GEKPLS:',otgekplssecondderivatives(xv))        



.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Predicted values by GEKPLS:     [ y0        ]
    0 : [  47.8136  ]
    1 : [ 109.4     ]
    2 : [  91.7283  ]
    3 : [  89.8216  ]
    4 : [   1.99044 ]
    5 : [  90.0777  ]
    6 : [  71.59    ]
    7 : [  55.032   ]
    8 : [  53.2398  ]
    9 : [  34.1366  ]
    Predicted variances values by GEKPLS:     [ y0          ]
    0 : [ 1.03025e-09 ]
    1 : [ 5.09603e-08 ]
    2 : [ 4.39519e-08 ]
    3 : [ 7.89523e-08 ]
    4 : [ 1.95515e-09 ]
    5 : [ 2.12462e-06 ]
    6 : [ 2.79333e-08 ]
    7 : [ 1.56964e-08 ]
    8 : [ 1.61617e-07 ]
    9 : [ 1.38781e-09 ]
    Predicted mean first derivatives by GEKPLS:     [ y0         ]
    0 : [  -8.73422  ]
    1 : [  10.6879   ]
    2 : [  14.5705   ]
    3 : [ -18.9169   ]
    4 : [  -1.30882  ]
    5 : [  18.4512   ]
    6 : [  -4.32487  ]
    7 : [ -12.5469   ]
    8 : [   0.406964 ]
    9 : [   7.11717  ]
    Predicted mean second derivatives by GEKPLS:     [ y0        ]
    0 : [ -10.7223  ]
    1 : [ -17.9826  ]
    2 : [  12.4344  ]
    3 : [  -1.19842 ]
    4 : [   2.49977 ]
    5 : [  -4.45807 ]
    6 : [  16.3602  ]
    7 : [   7.91864 ]
    8 : [ -14.5875  ]
    9 : [   9.26779 ]





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.138 seconds)


.. _sphx_glr_download_auto_example_plot_example_GEKPLS.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_example_GEKPLS.py <plot_example_GEKPLS.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_example_GEKPLS.ipynb <plot_example_GEKPLS.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
